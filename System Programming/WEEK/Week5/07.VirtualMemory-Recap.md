# **07.Virtual Memory - Recap Lecture Summary**

## **1. Motivation for Virtual Memory**

- **Memory Addressing Illusion**: Programs interact with a large, continuous memory space, but actual physical memory is limited and fragmented.
- **Problems Without VM**:
  - **Fitting everything**: Virtual addresses span 64-bit (16 exabytes), but physical memory is just a few GB.
  - **Memory management**: Need to manage memory across multiple processes.
  - **Protection**: One process should not corrupt another's memory.
  - **Sharing**: Need controlled sharing mechanisms.

&rarr; **Solution**: Introduce **indirection** via **virtual memory** (VM) that abstracts physical memory using mapping mechanisms.

## **2. Basic Concepts of Virtual Memory**

- **Virtual Memory (VM)** = Abstraction of physical memory.
- Every process gets its own **virtual address space** (VAS), isolated from others.
- **Address Translation**: VA &rarr; PA through a **mapping mechanism** maintained by the OS and enforced by hardware (MMU).
- **Translation unit**: Virtual address is broken into **Virtual Page Number (VPN)** and **Virtual Page Offset (VPO)**.

### Example:
```text
VA = 0x233 (hex)
Page size = 0x100 = 256 bytes
```
&rarr; VPN = 2 (0x233 / 0x100), VPO = 0x33
&rarr; If VPN 2 maps to PPN 5, then PA = 0x500 + 0x33 = 0x533

## **3. Page Tables and the MMU**

- Page Table: Maps each VPN to a Physical Page Number (PPN).
- Each entry in the table = Page Table Entry (PTE):
	- Valid bit, PPN, permission bits (R/W/U/S), dirty/reference bits.
- MMU:
  - Translates addresses using the Page Table.
	- Holds a pointer to the base of the page table (e.g., CR3 on x86).
- Translation is hardware-accelerated and time-sensitive.

## **4. Memory Hierarchy & Locality**

### **Hierarchical Storage Levels:**
- Registers
- L1/L2/L3 Caches (SRAM)
- Main Memory (DRAM)
- Secondary Storage (Disks, SSDs)
- Remote Storage (Web, DFS)

### **Locality Principles:**
- Temporal locality: Recently accessed data is likely to be reused soon.
- Spatial locality: Data near recently accessed locations is likely to be accessed.

&rarr; Caches exploit locality:
- Small, fast caches store frequently accessed blocks from slower memory.
- Page size (e.g., 4KB) chosen to balance cache effectiveness and overhead.

## **5. Cache**

### **5.1 Cache Block Sizes**
- Fixed vs. variable size
	- Fixed-size: easier to manage (common case)
	- Variable-size: efficient use of storage
- Block size
	- Block size is inversely proportional to access time of level k+1 device.

### **5.2 Cache Behavior in Memory Hierarchy**
- Cache Hit: Requested block is in cache → fast access.
- Cache Miss:
	- Cold miss: Block never accessed before.
	- Capacity miss: Cache is too small for the working set.
	- Conflict miss: Limited placement policy leads to eviction.
- Replacement Policies:
	- Optimal (unrealizable)
	- LRU (Least Recently Used): Approximated in practice (expensive to implement)
- Management Responsibility:
	- Registers: managed by compiler
	- L1/L2/L3 caches: managed by hardware
	- Main memory: managed by OS

## **6. Memory Management and Protection via VM**
- Per-process address space:
	- Each process has its own page table.
	- Shared memory via mapping same PPN to multiple processes.
- Decoupling of Virtual from Physical Address Space:
	- 64-bit process on much smaller physical memory (PS=4KB)
	- Lots of engineering problems:
		- how big is the page table?
		- multi-level page tables
		- security
		- isolation
		- sharing
		- avoid duplication
		-	lazy copy / copy on write (COW)
- Physical Memory as a Cache:
	- Use the disk for swapping ("on-demand paging")
	- Lots of engineering problems:
		- what happens when accessing address 0x233 in process A?
		- which page to replace when physical memory is full?
- Protection:
	- Permission bits in PTEs (R/W, User/Supervisor, XD)
	-	Violations trigger segmentation faults (e.g., SIGSEGV)
	
## **7. Motivating example**
- How can we make shared variable between other processes?
	- Using mmap()
	- Note: When accessing shared variables through mmap, you must take care to use proper locking.

## **8. Address Translation (VA &rarr; PA)**
- Address components:
	- VA = VPN + VPO
	- PA = PPN + PPO
	- Translation flow:
		1. VA is divided: VPN (page index) + VPO (offset)
		2. VPN is used to index page table.
		3. Get PPN from PTE, combine with VPO → get PA.
- Optimization:
	- Use Translation Lookaside Buffer (TLB):
		- Small cache for recently used PTEs.
		- Reduces memory accesses during translation.
		- TLB miss &rarr; fetch PTE from page table.

## **9. Multi-Level Page Tables**
- Necessary for managing huge address spaces (e.g., 64-bit).
- Organize page tables hierarchically:
	- Each level narrows down the physical location of the page.
	- Reduces memory usage by avoiding allocation of unneeded sub-tables.
	- Intel Core i7 uses 4-level paging.

&rarr; VA is broken into:
```text
VPN1 | VPN2 | VPN3 | VPN4 | VPO
Each VPN: 9 bits (4-levels), VPO: 12 bits (page size = 4KB)
```

## **10. Case Study: Intel Core i7**
- TLBs:
	- L1 Instruction TLB: 128 entries
	- L1 Data TLB: 64 entries
	- L2 Unified TLB: 512 entries
- Cache Hierarchy:
	- L1 I/D: 32 KB, 8-way
	- L2: 256 KB, 8-way
	- L3: 8 MB, 16-way (shared)
- Translation Path:
	1. CPU generates VA.
	2. Check TLB → hit/miss.
	3. Multi-level page table walk (if needed).
	4. Final PA sent to L1 cache.
- Page table entry format:
	- Includes access control bits (R/W, U/S, XD)
	- Includes status bits (A: accessed, D: dirty)

## **11. Summary of Virtual Memory Capabilities**
- Private Memory: Every process sees a large, isolated memory space.
- Shared Memory: Explicit mapping enables safe sharing between processes.
- Protection: Prevent illegal memory access via permission bits.
- Swapping: Only active memory resides in RAM; rest stays on disk.
- Simplified Program Loading: Demand paging + memory-mapped files.
- Fine-Grained Access Control: At the page level (4KB granularity).
- Powerful Programming Model: mmap, dynamic allocation, copy-on-write (COW), shared libraries, etc.

## **12. For Practice and Further Exploration**
- Try computing VA &rarr; PA translation for given VA bits, TLB size, page size.
- Simulate multi-process address mappings and detect protection faults.
- Observe page fault counts via getrusage() in Linux.
- Use tools like strace, vmstat, and perf to observe VM behavior in real systems.
